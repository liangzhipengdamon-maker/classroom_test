"""
InkSight æ•°å­—ç¬”è¿¹è¯†åˆ«å°è£…æ¨¡å—
é›†æˆ Google InkSight æ¨¡å‹è¿›è¡Œç¬”è¿¹åˆ†è§£ä¸ç¬”é¡ºæ¨ç†
"""

import os
import torch
import numpy as np
from PIL import Image
from pathlib import Path
import logging
from typing import Dict, List, Optional, Tuple

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

try:
    from transformers import AutoImageProcessor, AutoModelForImageClassification
except ImportError:
    logger.warning("transformers åº“æœªå®‰è£…ï¼Œéƒ¨åˆ†åŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·è¿è¡Œ: pip install transformers")


class InkSightExtractor:
    """
    InkSight ç¬”è¿¹æå–å™¨
    
    åŠŸèƒ½ï¼š
    - åŠ è½½ Google InkSight æ¨¡å‹ï¼ˆé€šè¿‡ Hugging Face Transformersï¼‰
    - å¤„ç†ä¹¦æ³•å›¾åƒå¹¶æå–æ•°å­—ç¬”è¿¹ä¿¡æ¯
    - è‡ªåŠ¨æ£€æµ‹ CPU/GPU è®¾å¤‡
    - åŒ…å«å®Œæ•´é”™è¯¯å¤„ç†
    """
    
    MODEL_NAME = "Derendering/InkSight-Small-p"
    CACHE_DIR = Path(__file__).parent / ".inksight_cache"
    
    def __init__(self, device: Optional[str] = None, use_cache: bool = True):
        """
        åˆå§‹åŒ– InkSight æå–å™¨
        
        Args:
            device: è®¡ç®—è®¾å¤‡ ('cpu'/'cuda'/'mps')ï¼ŒNone æ—¶è‡ªåŠ¨æ£€æµ‹
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹
        """
        self.device = device or self._detect_device()
        self.use_cache = use_cache
        self.model = None
        self.processor = None
        
        if self.use_cache:
            self.CACHE_DIR.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"âœ… InkSight æå–å™¨åˆå§‹åŒ– (Device: {self.device})")
    
    def _detect_device(self) -> str:
        """è‡ªåŠ¨æ£€æµ‹æœ€ä¼˜è®¡ç®—è®¾å¤‡"""
        if torch.cuda.is_available():
            device = "cuda"
        elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            device = "mps"
        else:
            device = "cpu"
        
        logger.info(f"ğŸ” è‡ªåŠ¨æ£€æµ‹è®¡ç®—è®¾å¤‡: {device}")
        return device
    
    def _load_model(self) -> Tuple:
        """
        åŠ è½½ InkSight æ¨¡å‹å’Œå¤„ç†å™¨
        
        Returns:
            (processor, model) å…ƒç»„
        """
        if self.model is not None and self.processor is not None:
            return self.processor, self.model
        
        try:
            logger.info(f"ğŸ¤– åŠ è½½ InkSight æ¨¡å‹: {self.MODEL_NAME}")
            
            # è®¾ç½®ç¼“å­˜ç›®å½•
            cache_dir = str(self.CACHE_DIR) if self.use_cache else None
            
            # åŠ è½½å¤„ç†å™¨å’Œæ¨¡å‹
            self.processor = AutoImageProcessor.from_pretrained(
                self.MODEL_NAME,
                cache_dir=cache_dir,
                trust_remote_code=True
            )
            
            self.model = AutoModelForImageClassification.from_pretrained(
                self.MODEL_NAME,
                cache_dir=cache_dir,
                trust_remote_code=True,
                device_map=self.device if self.device != "cpu" else None
            )
            
            if self.device != "cpu":
                self.model = self.model.to(self.device)
            
            self.model.eval()
            logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            return self.processor, self.model
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            raise RuntimeError(f"æ— æ³•åŠ è½½ InkSight æ¨¡å‹: {str(e)}")
    
    def extract_digital_ink(self, image_path: str) -> Dict:
        """
        ä»ä¹¦æ³•å›¾åƒæå–æ•°å­—ç¬”è¿¹æ•°æ®
        
        Args:
            image_path: è¾“å…¥å›¾åƒè·¯å¾„ (JPEG/PNG)
        
        Returns:
            å­—å…¸ï¼ŒåŒ…å«ï¼š
            - success: æ˜¯å¦æˆåŠŸæå–
            - image_path: è¾“å…¥å›¾åƒè·¯å¾„
            - device: ä½¿ç”¨çš„è®¡ç®—è®¾å¤‡
            - features: æå–çš„ç¬”è¿¹ç‰¹å¾å‘é‡ (list)
            - stroke_count: ä¼°è®¡ç¬”ç”»æ•°é‡
            - confidence: æ¨¡å‹ç½®ä¿¡åº¦
            - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
            - processing_time_ms: å¤„ç†è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
        """
        import time
        start_time = time.time()
        
        result = {
            "success": False,
            "image_path": image_path,
            "device": self.device,
            "features": [],
            "stroke_count": 0,
            "confidence": 0.0,
            "error": None,
            "processing_time_ms": 0
        }
        
        try:
            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
            # åŠ è½½å¹¶éªŒè¯å›¾åƒ
            image = Image.open(image_path)
            if image.mode != "RGB":
                image = image.convert("RGB")
            
            logger.info(f"ğŸ“¸ å¤„ç†å›¾åƒ: {image_path} (Size: {image.size})")
            
            # åŠ è½½æ¨¡å‹
            processor, model = self._load_model()
            
            # å›¾åƒé¢„å¤„ç†ä¸æ¨ç†
            with torch.no_grad():
                inputs = processor(images=image, return_tensors="pt")
                
                if self.device != "cpu":
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                # æ¨¡å‹æ¨ç†
                outputs = model(**inputs)
                
                # æå–ç‰¹å¾å’Œé¢„æµ‹
                logits = outputs.logits
                probabilities = torch.softmax(logits, dim=-1)
                
                # è·å–ç½®ä¿¡åº¦å’Œç±»åˆ«
                confidence, predicted_class = torch.max(probabilities, dim=-1)
                
                # æå–éšå±‚ç‰¹å¾ï¼ˆé€šå¸¸åœ¨æ¨¡å‹çš„å€’æ•°ç¬¬äºŒå±‚ï¼‰
                if hasattr(outputs, 'hidden_states') and outputs.hidden_states:
                    features = outputs.hidden_states[-1].mean(dim=1).detach().cpu().numpy()
                else:
                    # é™çº§å¤„ç†ï¼šä½¿ç”¨logitsä½œä¸ºç‰¹å¾å‘é‡
                    features = logits.detach().cpu().numpy()
                
                # ç»“æœæ”¶é›†
                result["success"] = True
                result["features"] = features.squeeze().tolist()
                result["confidence"] = float(confidence.item())
                result["stroke_count"] = int(predicted_class.item())
                
                logger.info(
                    f"âœ… ç¬”è¿¹æå–æˆåŠŸ | "
                    f"ç¬”ç”»æ•°: {result['stroke_count']} | "
                    f"ç½®ä¿¡åº¦: {result['confidence']:.4f}"
                )
        
        except FileNotFoundError as e:
            result["error"] = f"æ–‡ä»¶é”™è¯¯: {str(e)}"
            logger.error(result["error"])
        
        except torch.cuda.OutOfMemoryError as e:
            result["error"] = "GPU å†…å­˜ä¸è¶³ï¼Œå·²åˆ‡æ¢åˆ° CPU æ¨¡å¼"
            self.device = "cpu"
            logger.warning(result["error"])
            # å¯é€‰ï¼šé€’å½’é‡è¯•ä¸€æ¬¡
            return self.extract_digital_ink(image_path)
        
        except Exception as e:
            result["error"] = f"å¤„ç†å¤±è´¥: {str(e)}"
            logger.error(f"âŒ {result['error']}")
        
        finally:
            result["processing_time_ms"] = round((time.time() - start_time) * 1000, 2)
        
        return result
    
    def batch_extract(self, image_dir: str) -> List[Dict]:
        """
        æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„å›¾åƒ
        
        Args:
            image_dir: åŒ…å«å›¾åƒçš„ç›®å½•è·¯å¾„
        
        Returns:
            ç»“æœåˆ—è¡¨
        """
        results = []
        image_dir_path = Path(image_dir)
        
        if not image_dir_path.is_dir():
            logger.error(f"âŒ ç›®å½•ä¸å­˜åœ¨: {image_dir}")
            return results
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        image_files = list(image_dir_path.glob("*.jpg")) + \
                     list(image_dir_path.glob("*.jpeg")) + \
                     list(image_dir_path.glob("*.png"))
        
        logger.info(f"ğŸ”„ å¼€å§‹æ‰¹å¤„ç† {len(image_files)} å¼ å›¾åƒ")
        
        for idx, img_path in enumerate(image_files, 1):
            logger.info(f"å¤„ç†è¿›åº¦: {idx}/{len(image_files)}")
            result = self.extract_digital_ink(str(img_path))
            results.append(result)
        
        logger.info(f"âœ… æ‰¹å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {sum(1 for r in results if r['success'])}/{len(results)}")
        return results
    
    def cleanup(self):
        """æ¸…ç†å†…å­˜ä¸­çš„æ¨¡å‹"""
        if self.model is not None:
            self.model = None
        if self.processor is not None:
            self.processor = None
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        logger.info("ğŸ—‘ï¸ æ¨¡å‹èµ„æºå·²æ¸…ç†")


# å…¨å±€æå–å™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_extractor = None


def get_extractor(device: Optional[str] = None) -> InkSightExtractor:
    """è·å–å…¨å±€ InkSight æå–å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _extractor
    if _extractor is None:
        _extractor = InkSightExtractor(device=device)
    return _extractor


def extract_digital_ink(image_path: str, device: Optional[str] = None) -> Dict:
    """
    å¿«æ·å‡½æ•°ï¼šæå–å›¾åƒä¸­çš„æ•°å­—ç¬”è¿¹
    
    Args:
        image_path: å›¾åƒè·¯å¾„
        device: è®¡ç®—è®¾å¤‡
    
    Returns:
        æå–ç»“æœå­—å…¸
    """
    extractor = get_extractor(device=device)
    return extractor.extract_digital_ink(image_path)


if __name__ == "__main__":
    # æµ‹è¯•ç¤ºä¾‹
    logging.basicConfig(level=logging.INFO)
    
    print("InkSight å°è£…æ¨¡å—å·²å°±ç»ªï¼")
    print("\nä½¿ç”¨ç¤ºä¾‹:")
    print("  from utils.inksight_wrapper import extract_digital_ink")
    print("  result = extract_digital_ink('path/to/image.jpg')")
    print(f"  print(result)")
